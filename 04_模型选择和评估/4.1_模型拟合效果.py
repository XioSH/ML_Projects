# 4.1.1 欠拟合与过拟合表现方式
# 如何判断模型的拟合情况呢？针对这种情况，通常可以使用两种判断方案：
# 一是判断在训练集和测试集上的预测误差的差异大小，正常拟合的模型通常在训练集和测试集上的预测误差相差不大，而且预测效果均较好；
# 欠拟合模型在训练集和测试集上的预测效果均较差；过拟合模型则会在训练集上获得很小的预测误差，但是在测试集上会获得较大的预测误差。
# 二是可视化出模型在训练过程中，3种不同的数据拟合在训练数据和测试数据（或验证数据）上的损失函数变化情况

# 4.1.2 避免过拟合和欠拟合的方法
'''(1)增加数据量
# 如果训练数据较少，可能会导致数据欠拟合，偶尔也会发生在训练集上过拟合的问题。
# 因此较多的训练样本通常会使模型更加稳定，所以训练样本的增加不仅可以得到更有效的训练结果，也能在一定程度上调整模型的拟合效果，增强其泛化能力。
# 但是如果训练样本有限，也可以利用数据增强技术对现有的数据集进行扩充。
'''
'''(2)合理的数据切分
# 针对现有的数据集，在训练模型时，可以将数据集切分为训练集、验证集和测试集（或者使用交叉验证的方法）​。
# 在对数据进行切分后，可以使用训练集来训练模型，通过验证集监督模型的学习过程，也可以在网络过拟合之前提前终止模型的训练。在模型训练结束后，可以利用测试集来测试训练结果的泛化能力。
# 当然在保证数据尽可能地来自同一分布的情况下，如何有效地对数据集进行切分也很重要，传统的数据切分方法通常按照60：20：20的比例拆分
# 但是数据量不同，数据切分的比例也不尽相同，尤其在大数据时代，如果数据集有几百万甚至上亿级条目时，这种60：20：20比例的传统划分已经不再适合，更好的方式是将98%的数据集用于训练，保证尽可能多的样本接受训练，1%的样本用于验证集，这1%的数据已经有足够多的样本来监督模型是否过拟合，最后使用1%的样本测试网络的泛化能力。
# 所以，针对数据量的大小、网络参数的数量，数据的切分比例可以根据实际需要来确定。
'''
'''(3)正则化方法
# 正则化方法是解决模型过拟合问题的一种手段，其通常会在损失函数上添加对训练参数的范数惩罚，通过添加的范数惩罚对需要训练的参数进行约束，防止模型过拟合。
# 常用的正则化参数有l1和l2范数，l1范数惩罚的目的是将参数的绝对值最小化，l2范数惩罚的目的是将参数的平方和最小化。
# 使用正则化防止过拟合非常有效，在经典的线性回归模型中，使用l1范数正则化的模型叫作LASSO回归，使用l2范数正则化的模型叫作Ridge回归
'''